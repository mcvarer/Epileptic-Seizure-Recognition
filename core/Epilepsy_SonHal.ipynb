{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "## for Deep-learing:\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "import tensorflow\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D,Dense\n",
    "from keras.layers import Dropout,concatenate,Input,Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "#graphic\n",
    "import matplotlib.pyplot as plt\n",
    "#istatiski fonk\n",
    "import neurokit as nk\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...  X170  X171  X172  \\\n",
       "0  135  190  229  223  192  125   55   -9  -33  -38  ...   -17   -15   -31   \n",
       "1  386  382  356  331  320  315  307  272  244  232  ...   164   150   146   \n",
       "2  -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    57    64    48   \n",
       "3 -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -82   -81   -80   \n",
       "4   -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...     4     2   -12   \n",
       "\n",
       "   X173  X174  X175  X176  X177  X178  OUTPUT_LABEL  \n",
       "0   -77  -103  -127  -116   -83   -51             0  \n",
       "1   152   157   156   154   143   129             1  \n",
       "2    19   -12   -30   -35   -35   -36             0  \n",
       "3   -77   -85   -77   -72   -69   -65             0  \n",
       "4   -32   -41   -65   -83   -89   -73             0  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"OUTPUT_LABEL\"] = df.y == 1\n",
    "df[\"OUTPUT_LABEL\"] = df[\"OUTPUT_LABEL\"].astype(int)\n",
    "df.pop('y')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevalence of the positive class: 0.200\n",
      "# of Columns: 179\n"
     ]
    }
   ],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    # this function calculates the prevalence of the positive class (label = 1)\n",
    "    return sum(y_actual) / len(y_actual)\n",
    "\n",
    "\n",
    "print(\"prevalence of the positive class: %.3f\"\n",
    "    % calc_prevalence(df[\"OUTPUT_LABEL\"].values))\n",
    "\n",
    "print(\"# of Columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "collist = df.columns.tolist()\n",
    "cols_input = collist[0:178]\n",
    "df_data = df[cols_input + [\"OUTPUT_LABEL\"]]\n",
    "\n",
    "# check for duplicated columns in cols_input\n",
    "dup_cols = set([x for x in cols_input if cols_input.count(x) > 1])\n",
    "print(dup_cols)\n",
    "assert len(dup_cols) == 0, \"you have duplicated columns in cols_input\"\n",
    "\n",
    "# check for duplicated columns in df_data\n",
    "cols_df_data = list(df_data.columns)\n",
    "dup_cols = set([x for x in cols_df_data if cols_df_data.count(x) > 1])\n",
    "print(dup_cols)\n",
    "assert len(dup_cols) == 0,'you have duplicated columns in df_data'\n",
    "\n",
    "# check the size of df_data makes sense\n",
    "assert (len(cols_input) + 1) == len(\n",
    "    df_data.columns\n",
    "), \"issue with dimensions of df_data or cols_input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation/Test Split Size: 0.3\n"
     ]
    }
   ],
   "source": [
    "df_data = df_data.sample(n=len(df_data))\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "df_valid_test = df_data.sample(frac=0.3)\n",
    "print(\"Validation/Test Split Size: %.1f\" % (len(df_valid_test) / len(df_data)))\n",
    "\n",
    "df_test = df_valid_test.sample(frac=0.5)\n",
    "df_valid = df_valid_test.drop(df_test.index)\n",
    "\n",
    "df_train_all = df_data.drop(df_valid_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prevalence(n = 1725):0.192\n",
      "Valid prevalence(n = 1725):0.197\n",
      "Train all prevalence(n = 8050):0.202\n"
     ]
    }
   ],
   "source": [
    "# check the prevalence of each\n",
    "print(\n",
    "    \"Test prevalence(n = %d):%.3f\"\n",
    "    % (len(df_test), calc_prevalence(df_test.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Valid prevalence(n = %d):%.3f\"\n",
    "    % (len(df_valid), calc_prevalence(df_valid.OUTPUT_LABEL.values))\n",
    ")\n",
    "print(\n",
    "    \"Train all prevalence(n = %d):%.3f\"\n",
    "    % (len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples (n = 11500)\n"
     ]
    }
   ],
   "source": [
    "print('all samples (n = %d)'%len(df_data))\n",
    "assert len(df_data) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced prevalence(n = 3260):0.500\n"
     ]
    }
   ],
   "source": [
    "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "n = np.min([len(df_train_pos), len(df_train_neg)])\n",
    "\n",
    "df_train = pd.concat([df_train_pos.sample(n=n, random_state=69), df_train_neg.sample(n=n, random_state=69)], axis=0, ignore_index=True)\n",
    "\n",
    "df_train = df_train.sample(n=len(df_train), random_state=69).reset_index(drop=True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all.to_csv('df_train_all.csv',index=False)\n",
    "df_train.to_csv('df_train.csv',index=False)\n",
    "df_valid.to_csv('df_valid.csv',index=False)\n",
    "df_test.to_csv('df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cols_input, open('cols_input.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to fill missing values with mean of the column if needed\n",
    "def fill_my_missing(df, df_mean, col2use):\n",
    "    # This function fills the missing values\n",
    "\n",
    "    # check the columns are present\n",
    "    for c in col2use:\n",
    "        assert c in df.columns, c + ' not in df'\n",
    "        assert c in df_mean.col.values, c+ 'not in df_mean'\n",
    "    \n",
    "    # replace the mean \n",
    "    for c in col2use:\n",
    "        mean_value = df_mean.loc[df_mean.col == c,'mean_val'].values[0]\n",
    "        df[c] = df[c].fillna(mean_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training All shapes: (8050, 178)\n",
      "XTrain shapes, YTrain shapes: (4985, 178) (4985,)\n"
     ]
    }
   ],
   "source": [
    "# create the X and y matrices\n",
    "X_train = df_train[cols_input].values\n",
    "X_train_all = df_train_all[cols_input].values\n",
    "X_valid = df_valid[cols_input].values\n",
    "\n",
    "XTrain = np.concatenate((X_train, X_valid), axis=0)\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n",
    "YTrain = np.concatenate((y_train, y_valid), axis=0)\n",
    "\n",
    "print('Training All shapes:',X_train_all.shape)\n",
    "# print('Training shapes:',X_train.shape, y_train.shape)\n",
    "print('XTrain shapes, YTrain shapes:',XTrain.shape, YTrain.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train_all)\n",
    "\n",
    "scalerfile = 'scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))\n",
    "scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "# transform our data matrices\n",
    "X_train_tf = scaler.transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity[0])\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity \n",
    "thres=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ä°statistik FonksiyonlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth(a):\n",
    "    first_deriv = np.diff(a)\n",
    "    second_deriv = np.diff(a,2)\n",
    "\n",
    "    var_zero = np.mean(a ** 2)\n",
    "    var_d1 = np.mean(first_deriv ** 2)\n",
    "    var_d2 = np.mean(second_deriv ** 2)\n",
    "\n",
    "    activity = var_zero\n",
    "    morbidity = np.sqrt(var_d1 / var_zero)\n",
    "    complexity = np.sqrt(var_d2 / var_d1) / morbidity\n",
    "\n",
    "    return activity, morbidity, complexity\n",
    "\n",
    "def medianNorm(a):\n",
    "    median = np.median(a)\n",
    "    #print(median)\n",
    "    xi = np.zeros((len(a)))\n",
    "    #print(len(a))\n",
    "    for i in range(len(a)):\n",
    "        x = a[i]/median\n",
    "        #print(x)\n",
    "        xi[i] = x\n",
    "        \n",
    "    return xi\n",
    "\n",
    "def maxminNorm(a):\n",
    "    maxx = np.amax(a)\n",
    "    minn = np.amin(a)\n",
    "    xi = np.zeros((len(a)))\n",
    "    for i in range(len(a)):\n",
    "        val = (a[i] - minn ) / (maxx - minn)\n",
    "        xi[i] = val\n",
    "    return xi\n",
    "\n",
    "def stDevNorm(a):\n",
    "    mean = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    xi = np.zeros((len(a)))\n",
    "    for i in range(len(a)):\n",
    "        val = ( a[i] - mean) / std\n",
    "        xi[i] = val\n",
    "    return xi\n",
    "\n",
    "def sigmoidNorm(a):\n",
    "    xi = np.zeros((len(a)))\n",
    "    for i in range(len(a)):\n",
    "        up = np.exp(a[i]) - np.exp(-a[i])\n",
    "        down = np.exp(a[i]) + np.exp(-a[i])\n",
    "        xi[i] = up / down\n",
    "    return xi\n",
    "def DmaxminNorm(a):\n",
    "    maxx = np.amax(a)\n",
    "    minn = np.amin(a)\n",
    "    xi = np.zeros((len(a)))\n",
    "    for i in range(len(a)):\n",
    "        val = (0.8*(a[i] - minn ) ) / (maxx - minn)\n",
    "        xi[i] = val + 0.1\n",
    "    return xi\n",
    "def zeroCrossing(a):\n",
    "    zcr = 0\n",
    "    sgn = np.zeros((len(a)-1))\n",
    "    for i in range(len(a)-1):\n",
    "        sgn[i] = a[i]/a[i+1]\n",
    "        if(sgn[i] < 0):\n",
    "            zcr +=1\n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['Mean_time', 'StandarS_time','Kurt_time',\n",
    "               'Skewness_time','Activity_time', 'Complexity_time','Morbidity_time','Mad_time']\n",
    "Y_columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st = pd.DataFrame(columns = X_columns)\n",
    "y_train_st = pd.DataFrame(columns = Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_time</th>\n",
       "      <th>StandarS_time</th>\n",
       "      <th>Kurt_time</th>\n",
       "      <th>Skewness_time</th>\n",
       "      <th>Activity_time</th>\n",
       "      <th>Complexity_time</th>\n",
       "      <th>Morbidity_time</th>\n",
       "      <th>Mad_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.019894</td>\n",
       "      <td>0.680175</td>\n",
       "      <td>0.989738</td>\n",
       "      <td>1.315704</td>\n",
       "      <td>0.463034</td>\n",
       "      <td>0.362118</td>\n",
       "      <td>2.058017</td>\n",
       "      <td>0.289498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.241755</td>\n",
       "      <td>0.567382</td>\n",
       "      <td>-0.127283</td>\n",
       "      <td>-0.431650</td>\n",
       "      <td>0.380368</td>\n",
       "      <td>0.428916</td>\n",
       "      <td>1.433007</td>\n",
       "      <td>0.318595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_time  StandarS_time  Kurt_time  Skewness_time  Activity_time  \\\n",
       "0  -0.019894       0.680175   0.989738       1.315704       0.463034   \n",
       "1  -0.241755       0.567382  -0.127283      -0.431650       0.380368   \n",
       "\n",
       "   Complexity_time  Morbidity_time  Mad_time  \n",
       "0         0.362118        2.058017  0.289498  \n",
       "1         0.428916        1.433007  0.318595  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(XTrain.shape[0]):\n",
    "    activity, morbidity, complexity = hjorth(X_train_tf[i])\n",
    "    mad = nk.mad(X_train_tf[i])\n",
    "    X_train_st.loc[i] = np.array([np.mean(X_train_tf[i]), np.std(X_train_tf[i]), \n",
    "                                         scipy.stats.kurtosis(X_train_tf[i]),\n",
    "                                         scipy.stats.skew(X_train_tf[i]),\n",
    "                                         activity, morbidity, complexity, mad])\n",
    "    y_train_st.loc[i] = YTrain[i]\n",
    "X_train_st.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st.to_csv('X_train_st.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4985, 1, 178)\n"
     ]
    }
   ],
   "source": [
    "X_train_tf = X_train_tf.reshape((X_train_tf.shape[0], 1,X_train_tf.shape[1]))\n",
    "\n",
    "print(X_train_tf.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_zm = np.copy(X_train_tf)\n",
    "# X_train_zm = X_train_zm.reshape((X_train_zm.shape[0],X_train_zm.shape[2]))\n",
    "# zmarr = []\n",
    "# for i in range(X_train_zm.shape[0]):\n",
    "#     cr_row = X_train_zm[i,:]\n",
    "#     #print(cr_row.shape)\n",
    "#     cr_row = cr_row.reshape(178,1)\n",
    "#     # print(cr_row.shape)      \n",
    "#     zm = mh.features.zernike_moments(cr_row,1,19)\n",
    "#     zmarr.append(zm)\n",
    "    \n",
    "# print(np.asarray(zmarr).shape)\n",
    "# X_train_zmoment = np.asarray(zmarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output=1):\n",
    "    inputA = Input(shape=(1,178),name=\"LSTM_input\")\n",
    "    inputB = Input(shape=(8,),name=\"STATS_input\")\n",
    "    \n",
    "    x = LSTM(120,return_sequences=True)(inputA)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu', name='layer1')(x)\n",
    "    x = Dense(64, activation='relu', name='layer2')(x)\n",
    "    x = Model(inputs=inputA, outputs=x)\n",
    "      \n",
    "    y = Dense(128, activation='relu', name='layer_1')(inputB)\n",
    "    y = Dense(64, activation='relu', name='layer_2')(y)\n",
    "    y = Model(inputs=inputB, outputs=y)\n",
    "    \n",
    "    combined = concatenate([x.output,y.output])\n",
    "    \n",
    "    z = Dense(32, activation=\"relu\")(combined)\n",
    "    # z = Dense(8, activation=\"relu\")(z)\n",
    "    z = Dense(output, activation=\"sigmoid\")(z)\n",
    "\n",
    "\n",
    "    model = Model(inputs = [x.input,y.input], outputs=z)\n",
    "    adam = Adam(1e-3)\n",
    "    rmsprop = RMSprop(1e-3)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mcv/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "4985/4985 [==============================] - 2s 373us/step - loss: 0.0476 - accuracy: 0.9452\n",
      "Epoch 2/100\n",
      "4985/4985 [==============================] - 1s 236us/step - loss: 0.0207 - accuracy: 0.9761\n",
      "Epoch 3/100\n",
      "4985/4985 [==============================] - 1s 247us/step - loss: 0.0160 - accuracy: 0.9809\n",
      "Epoch 4/100\n",
      "4985/4985 [==============================] - 1s 243us/step - loss: 0.0147 - accuracy: 0.9831\n",
      "Epoch 5/100\n",
      "4985/4985 [==============================] - 1s 235us/step - loss: 0.0134 - accuracy: 0.9844\n",
      "Epoch 6/100\n",
      "4985/4985 [==============================] - 1s 232us/step - loss: 0.0113 - accuracy: 0.9878\n",
      "Epoch 7/100\n",
      "4985/4985 [==============================] - 1s 239us/step - loss: 0.0087 - accuracy: 0.9910\n",
      "Epoch 8/100\n",
      "4985/4985 [==============================] - 1s 239us/step - loss: 0.0099 - accuracy: 0.9876\n",
      "Epoch 9/100\n",
      "4985/4985 [==============================] - 1s 229us/step - loss: 0.0091 - accuracy: 0.9902\n",
      "Epoch 10/100\n",
      "4985/4985 [==============================] - 1s 242us/step - loss: 0.0093 - accuracy: 0.9902\n",
      "Epoch 11/100\n",
      "4985/4985 [==============================] - 1s 250us/step - loss: 0.0089 - accuracy: 0.9900\n",
      "Epoch 12/100\n",
      "4985/4985 [==============================] - 1s 232us/step - loss: 0.0075 - accuracy: 0.9920\n",
      "Epoch 13/100\n",
      "4985/4985 [==============================] - 1s 232us/step - loss: 0.0068 - accuracy: 0.9932\n",
      "Epoch 14/100\n",
      "4985/4985 [==============================] - 1s 261us/step - loss: 0.0083 - accuracy: 0.9902\n",
      "Epoch 15/100\n",
      "4985/4985 [==============================] - 1s 241us/step - loss: 0.0081 - accuracy: 0.9912\n",
      "Epoch 16/100\n",
      "4985/4985 [==============================] - 1s 237us/step - loss: 0.0077 - accuracy: 0.9912\n",
      "Epoch 17/100\n",
      "4985/4985 [==============================] - 1s 256us/step - loss: 0.0072 - accuracy: 0.9924\n",
      "Epoch 18/100\n",
      "4985/4985 [==============================] - 1s 260us/step - loss: 0.0069 - accuracy: 0.9924\n",
      "Epoch 19/100\n",
      "4985/4985 [==============================] - 1s 278us/step - loss: 0.0059 - accuracy: 0.9936\n",
      "Epoch 20/100\n",
      "4985/4985 [==============================] - 1s 256us/step - loss: 0.0059 - accuracy: 0.9934\n",
      "Epoch 21/100\n",
      "4985/4985 [==============================] - 1s 265us/step - loss: 0.0062 - accuracy: 0.9932\n",
      "Epoch 22/100\n",
      "4985/4985 [==============================] - 1s 272us/step - loss: 0.0054 - accuracy: 0.9942\n",
      "Epoch 23/100\n",
      "4985/4985 [==============================] - 1s 271us/step - loss: 0.0067 - accuracy: 0.9930\n",
      "Epoch 24/100\n",
      "4985/4985 [==============================] - 1s 231us/step - loss: 0.0064 - accuracy: 0.9930\n",
      "Epoch 25/100\n",
      "4985/4985 [==============================] - 1s 238us/step - loss: 0.0057 - accuracy: 0.9938\n",
      "Epoch 26/100\n",
      "4985/4985 [==============================] - 1s 256us/step - loss: 0.0050 - accuracy: 0.9946\n",
      "Epoch 27/100\n",
      "4985/4985 [==============================] - 1s 272us/step - loss: 0.0061 - accuracy: 0.9938\n",
      "Epoch 28/100\n",
      "4985/4985 [==============================] - 1s 258us/step - loss: 0.0057 - accuracy: 0.9944\n",
      "Epoch 29/100\n",
      "4985/4985 [==============================] - 1s 246us/step - loss: 0.0056 - accuracy: 0.9942\n",
      "Epoch 30/100\n",
      "4985/4985 [==============================] - 1s 244us/step - loss: 0.0058 - accuracy: 0.9938\n",
      "Epoch 31/100\n",
      "4985/4985 [==============================] - 1s 238us/step - loss: 0.0049 - accuracy: 0.9948\n",
      "Epoch 32/100\n",
      "4985/4985 [==============================] - 1s 230us/step - loss: 0.0070 - accuracy: 0.9922\n",
      "Epoch 33/100\n",
      "4985/4985 [==============================] - 1s 258us/step - loss: 0.0058 - accuracy: 0.9932\n",
      "Epoch 34/100\n",
      "4985/4985 [==============================] - 1s 234us/step - loss: 0.0048 - accuracy: 0.9950\n",
      "Epoch 35/100\n",
      "4985/4985 [==============================] - 1s 258us/step - loss: 0.0055 - accuracy: 0.9940\n",
      "Epoch 36/100\n",
      "4985/4985 [==============================] - 1s 246us/step - loss: 0.0055 - accuracy: 0.9934\n",
      "Epoch 37/100\n",
      "4985/4985 [==============================] - 2s 309us/step - loss: 0.0048 - accuracy: 0.9950\n",
      "Epoch 38/100\n",
      "4985/4985 [==============================] - 1s 251us/step - loss: 0.0043 - accuracy: 0.9956\n",
      "Epoch 39/100\n",
      "4985/4985 [==============================] - 1s 260us/step - loss: 0.0052 - accuracy: 0.9944\n",
      "Epoch 40/100\n",
      "4985/4985 [==============================] - 1s 264us/step - loss: 0.0040 - accuracy: 0.9960\n",
      "Epoch 41/100\n",
      "4985/4985 [==============================] - 1s 268us/step - loss: 0.0040 - accuracy: 0.9960\n",
      "Epoch 42/100\n",
      "4985/4985 [==============================] - 1s 239us/step - loss: 0.0043 - accuracy: 0.9956\n",
      "Epoch 43/100\n",
      "4985/4985 [==============================] - 1s 248us/step - loss: 0.0049 - accuracy: 0.9948\n",
      "Epoch 44/100\n",
      "4985/4985 [==============================] - 1s 274us/step - loss: 0.0040 - accuracy: 0.9956\n",
      "Epoch 45/100\n",
      "4985/4985 [==============================] - 1s 280us/step - loss: 0.0048 - accuracy: 0.9948\n",
      "Epoch 46/100\n",
      "4985/4985 [==============================] - 1s 269us/step - loss: 0.0033 - accuracy: 0.9966\n",
      "Epoch 47/100\n",
      "4985/4985 [==============================] - 1s 250us/step - loss: 0.0035 - accuracy: 0.9964\n",
      "Epoch 48/100\n",
      "4985/4985 [==============================] - 1s 253us/step - loss: 0.0040 - accuracy: 0.9954\n",
      "Epoch 49/100\n",
      "4985/4985 [==============================] - 1s 255us/step - loss: 0.0045 - accuracy: 0.9950\n",
      "Epoch 50/100\n",
      "4985/4985 [==============================] - 1s 246us/step - loss: 0.0038 - accuracy: 0.9960\n",
      "Epoch 51/100\n",
      "4985/4985 [==============================] - 1s 249us/step - loss: 0.0047 - accuracy: 0.9948\n",
      "Epoch 52/100\n",
      "4985/4985 [==============================] - 1s 252us/step - loss: 0.0058 - accuracy: 0.9934\n",
      "Epoch 53/100\n",
      "4985/4985 [==============================] - 1s 266us/step - loss: 0.0052 - accuracy: 0.9942\n",
      "Epoch 54/100\n",
      "4985/4985 [==============================] - 1s 233us/step - loss: 0.0041 - accuracy: 0.9958\n",
      "Epoch 55/100\n",
      "4985/4985 [==============================] - 1s 247us/step - loss: 0.0038 - accuracy: 0.9962\n",
      "Epoch 56/100\n",
      "4985/4985 [==============================] - 1s 239us/step - loss: 0.0041 - accuracy: 0.9958\n",
      "Epoch 57/100\n",
      "4985/4985 [==============================] - 1s 282us/step - loss: 0.0039 - accuracy: 0.9960\n",
      "Epoch 58/100\n",
      "4985/4985 [==============================] - 1s 233us/step - loss: 0.0063 - accuracy: 0.9930\n",
      "Epoch 59/100\n",
      "4985/4985 [==============================] - 1s 236us/step - loss: 0.0041 - accuracy: 0.9958\n",
      "Epoch 60/100\n",
      "4985/4985 [==============================] - 1s 235us/step - loss: 0.0042 - accuracy: 0.9960\n",
      "Epoch 61/100\n",
      "4985/4985 [==============================] - 1s 235us/step - loss: 0.0047 - accuracy: 0.9948\n",
      "Epoch 62/100\n",
      "4985/4985 [==============================] - 1s 236us/step - loss: 0.0034 - accuracy: 0.9964\n",
      "Epoch 63/100\n",
      "4985/4985 [==============================] - 1s 236us/step - loss: 0.0035 - accuracy: 0.9964\n",
      "Epoch 64/100\n",
      "4985/4985 [==============================] - 1s 235us/step - loss: 0.0035 - accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "4985/4985 [==============================] - 1s 237us/step - loss: 0.0053 - accuracy: 0.9944\n",
      "Epoch 66/100\n",
      "4985/4985 [==============================] - 1s 237us/step - loss: 0.0048 - accuracy: 0.9946\n",
      "Epoch 67/100\n",
      "4985/4985 [==============================] - 1s 239us/step - loss: 0.0043 - accuracy: 0.9954\n",
      "Epoch 68/100\n",
      "4985/4985 [==============================] - 1s 286us/step - loss: 0.0040 - accuracy: 0.9956\n",
      "Epoch 69/100\n",
      "4985/4985 [==============================] - 1s 255us/step - loss: 0.0039 - accuracy: 0.9960\n",
      "Epoch 70/100\n",
      "4985/4985 [==============================] - 1s 265us/step - loss: 0.0029 - accuracy: 0.9972\n",
      "Epoch 71/100\n",
      "4985/4985 [==============================] - 2s 304us/step - loss: 0.0030 - accuracy: 0.9968\n",
      "Epoch 72/100\n",
      "4985/4985 [==============================] - 2s 308us/step - loss: 0.0034 - accuracy: 0.9964\n",
      "Epoch 73/100\n",
      "4985/4985 [==============================] - 1s 242us/step - loss: 0.0026 - accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "4985/4985 [==============================] - 1s 255us/step - loss: 0.0035 - accuracy: 0.9962\n",
      "Epoch 75/100\n",
      "4985/4985 [==============================] - 2s 332us/step - loss: 0.0037 - accuracy: 0.9962\n",
      "Epoch 76/100\n",
      "4985/4985 [==============================] - 1s 275us/step - loss: 0.0035 - accuracy: 0.9962\n",
      "Epoch 77/100\n",
      "4985/4985 [==============================] - 1s 276us/step - loss: 0.0029 - accuracy: 0.9968\n",
      "Epoch 78/100\n",
      "4985/4985 [==============================] - 2s 328us/step - loss: 0.0031 - accuracy: 0.9968\n",
      "Epoch 79/100\n",
      "4985/4985 [==============================] - 1s 272us/step - loss: 0.0029 - accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "4985/4985 [==============================] - 1s 232us/step - loss: 0.0028 - accuracy: 0.9968\n",
      "Epoch 81/100\n",
      "4985/4985 [==============================] - 1s 222us/step - loss: 0.0035 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "4985/4985 [==============================] - 2s 313us/step - loss: 0.0028 - accuracy: 0.9972\n",
      "Epoch 83/100\n",
      "4985/4985 [==============================] - 2s 353us/step - loss: 0.0026 - accuracy: 0.9972\n",
      "Epoch 84/100\n",
      "4985/4985 [==============================] - 2s 388us/step - loss: 0.0024 - accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "4985/4985 [==============================] - 2s 423us/step - loss: 0.0026 - accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "4985/4985 [==============================] - 2s 388us/step - loss: 0.0027 - accuracy: 0.9974\n",
      "Epoch 87/100\n",
      "4985/4985 [==============================] - 2s 347us/step - loss: 0.0030 - accuracy: 0.9968\n",
      "Epoch 88/100\n",
      "4985/4985 [==============================] - 1s 298us/step - loss: 0.0027 - accuracy: 0.9974\n",
      "Epoch 89/100\n",
      "4985/4985 [==============================] - 1s 251us/step - loss: 0.0037 - accuracy: 0.9962\n",
      "Epoch 90/100\n",
      "4985/4985 [==============================] - 1s 284us/step - loss: 0.0026 - accuracy: 0.9972\n",
      "Epoch 91/100\n",
      "4985/4985 [==============================] - 1s 279us/step - loss: 0.0029 - accuracy: 0.9970\n",
      "Epoch 92/100\n",
      "4985/4985 [==============================] - 1s 225us/step - loss: 0.0049 - accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "4985/4985 [==============================] - 1s 210us/step - loss: 0.0055 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "4985/4985 [==============================] - 1s 218us/step - loss: 0.0044 - accuracy: 0.9954\n",
      "Epoch 95/100\n",
      "4985/4985 [==============================] - 1s 213us/step - loss: 0.0034 - accuracy: 0.9966\n",
      "Epoch 96/100\n",
      "4985/4985 [==============================] - 1s 224us/step - loss: 0.0034 - accuracy: 0.9962\n",
      "Epoch 97/100\n",
      "4985/4985 [==============================] - 1s 213us/step - loss: 0.0028 - accuracy: 0.9970\n",
      "Epoch 98/100\n",
      "4985/4985 [==============================] - 1s 218us/step - loss: 0.0034 - accuracy: 0.9966\n",
      "Epoch 99/100\n",
      "4985/4985 [==============================] - 1s 217us/step - loss: 0.0033 - accuracy: 0.9966\n",
      "Epoch 100/100\n",
      "4985/4985 [==============================] - 1s 228us/step - loss: 0.0027 - accuracy: 0.9972\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='loss', patience=15,mode='min')]\n",
    "\n",
    "history = model.fit([X_train_tf,X_train_st], YTrain, epochs=100, batch_size=32, \n",
    "                     verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOW9x/HPL8kkgRAIJGHfwr4JKIvIolarAi7Y64Z1r0utpWqtt1d79VrtctXbVmu1KgpKqaBWpYKCuCCCIkvYd4GwJKxhSchC9uf+MSchhMkGDIPJ9/16+XLmzDkzv5MBvnmW8xxzziEiIlKVsFAXICIiZz6FhYiIVEthISIi1VJYiIhItRQWIiJSLYWFiIhUS2EhcpLM7E0z+30N991mZj882fcROd0UFiIiUi2FhYiIVEthIfWC1/3zn2a2ysxyzGyCmbUws1lmlmVmn5tZ03L7X2Vma80sw8zmmlnPcq+dbWbLvOPeAaIrfNYVZrbCO3aBmfU9wZrvNrPNZnbQzKabWWtvu5nZc2a2z8wyvXPq47022szWebXtNLOHT+gHJlKBwkLqk2uAS4BuwJXALOA3QAL+vwv3A5hZN2Aq8CCQCMwEZphZpJlFAv8GJgPNgH9574t37DnAROCnQDzwKjDdzKJqU6iZXQT8L3A90ArYDrztvXwpcL53HnHADcAB77UJwE+dc7FAH2BObT5XpDIKC6lP/uac2+uc2wnMBxY555Y75/KBacDZ3n43AB875z5zzhUCfwIaAEOBIYAPeN45V+icew9YUu4z7gZedc4tcs4VO+cmAfnecbVxEzDRObfMq+9R4Dwz6wgUArFAD8Ccc+udc7u94wqBXmbW2Dl3yDm3rJafKxKQwkLqk73lHh8J8LyR97g1/t/kAXDOlQCpQBvvtZ3u2BU4t5d73AH4ldcFlWFmGUA777jaqFhDNv7WQxvn3BzgReAlYK+ZjTezxt6u1wCjge1m9pWZnVfLzxUJSGEhcrxd+P/RB/xjBPj/wd8J7AbaeNtKtS/3OBX4g3Murtx/DZ1zU0+yhhj83Vo7AZxzLzjnBgC98XdH/ae3fYlzbgzQHH932bu1/FyRgBQWIsd7F7jczC42Mx/wK/xdSQuAb4Ei4H4zizCz/wAGlzv2NeBeMzvXG4iOMbPLzSy2ljVMAe4ws/7eeMcf8XebbTOzQd77+4AcIA8o9sZUbjKzJl732WGg+CR+DiJlFBYiFTjnNgI3A38D9uMfDL/SOVfgnCsA/gO4HTiEf3zjg3LHJuMft3jRe32zt29ta/gCeBx4H39rpjMw1nu5Mf5QOoS/q+oA/nEVgFuAbWZ2GLjXOw+Rk2a6+ZGIiFRHLQsREalWUMPCzEaa2UbvwqJHArweZWbveK8v8qYFYmYdzeyId2HTCjN7JZh1iohI1SKC9cZmFo5/at8lQBqwxMymO+fWldvtTuCQc66LmY0FnsHfBwywxTnXP1j1iYhIzQWzZTEY2OycS/EGBd8GxlTYZwwwyXv8HnBxhSmJIiJyBghaywL/BUyp5Z6nAedWto9zrsjMMvHPJQdIMrPl+Kf/Peacm1/xA8zsHuAegJiYmAE9evQ4tWcgIlLHLV26dL9zLrG6/YIZFoFaCBWnXlW2z26gvXPugJkNAP5tZr2dc4eP2dG58cB4gIEDB7rk5ORTULaISP1hZtur3yu43VBp+K96LdUW/1WpAfcxswigCXDQOZfvnDsA4JxbCmzBf5WqiIiEQDDDYgnQ1cySvJU6xwLTK+wzHbjNe3wtMMc558ws0Rsgx8w6AV2BlCDWKiIiVQhaN5Q3BjEOmA2E419Bc62ZPQUkO+em419OebKZbQYOcvQK1fOBp8ysCP9yBfc65w4Gq1YREalanbmCW2MWInIiCgsLSUtLIy8vL9SlBFV0dDRt27bF5/Mds93MljrnBlZ3fDAHuEVEznhpaWnExsbSsWNH6urMfeccBw4cIC0tjaSkpBN6Dy33ISL1Wl5eHvHx8XU2KADMjPj4+JNqPSksRKTeq8tBUepkz7Heh8XuzCP8+dONpKRnh7oUEZEzVr0Pi/SsfP42ZzMp6TmhLkVE6qGMjAz+/ve/1/q40aNHk5GREYSKAqv3YeEL9/8ICotLQlyJiNRHlYVFcXHVNzmcOXMmcXFxwSrrOPV+NlRkhD8sChQWIhICjzzyCFu2bKF///74fD4aNWpEq1atWLFiBevWrePqq68mNTWVvLw8HnjgAe655x4AOnbsSHJyMtnZ2YwaNYrhw4ezYMEC2rRpw4cffkiDBg1OaZ0KC69lkV+ksBCp756csZZ1uw5Xv2Mt9GrdmCeu7F3p608//TRr1qxhxYoVzJ07l8svv5w1a9aUTXGdOHEizZo148iRIwwaNIhrrrmG+Pj4Y95j06ZNTJ06lddee43rr7+e999/n5tvPrV31K33YREVoW4oETlzDB48+JhrIV544QWmTZsGQGpqKps2bTouLJKSkujf33/7nwEDBrBt27ZTXle9D4vSMYsCtSxE6r2qWgCnS0xMTNnjuXPn8vnnn/Ptt9/SsGFDLrzwwoDXSkRFRZU9Dg8P58iRI6e8rno/wF02ZqGwEJEQiI2NJSsrK+BrmZmZNG3alIYNG7JhwwYWLlx4mqs7qt63LBQWIhJK8fHxDBs2jD59+tCgQQNatGhR9trIkSN55ZVX6Nu3L927d2fIkCEhq7Peh0VEmP+qRo1ZiEioTJkyJeD2qKgoZs2aFfC10nGJhIQE1qxZU7b94YcfPuX1gbqhMDMiI8LIV1iIiFSq3ocFQFR4mLqhRESqoLAAfBFh6oYSqcfqyn19qnKy56iwwH9hnloWIvVTdHQ0Bw4cqNOBUXo/i+jo6BN+j3o/wA3+GVEKC5H6qW3btqSlpZGenh7qUoKq9E55J0phAfjCjcLiuvtbhYhUzufznfDd4+oTdUMBkRHhWhtKRKQKCgu8bigNcIuIVEphQenU2arXjhcRqc8UFoAvQmMWIiJVUVigqbMiItVRWKCpsyIi1VFY4L+nha7gFhGpnMICf8tCU2dFRCqnsMB/a1VNnRURqZzCAnVDiYhUR2GBZkOJiFRHYYFmQ4mIVEdhgb8bqqjEUVKiC/NERAJRWOBvWQAa5BYRqYTCAv9sKFBYiIhUJqhhYWYjzWyjmW02s0cCvB5lZu94ry8ys44VXm9vZtlm9nAw6yxrWWjcQkQkoKCFhZmFAy8Bo4BewI1m1qvCbncCh5xzXYDngGcqvP4cMCtYNZbyhft/DJo+KyISWDBbFoOBzc65FOdcAfA2MKbCPmOASd7j94CLzcwAzOxqIAVYG8QaAf/UWVDLQkSkMsEMizZAarnnad62gPs454qATCDezGKA/wKeDGJ9ZdQNJSJStWCGhQXYVnFuamX7PAk855zLrvIDzO4xs2QzSz6Zm62XdkNpgFtEJLCIIL53GtCu3PO2wK5K9kkzswigCXAQOBe41syeBeKAEjPLc869WP5g59x4YDzAwIEDT/giiSi1LEREqhTMsFgCdDWzJGAnMBb4cYV9pgO3Ad8C1wJznHMOGFG6g5n9FsiuGBSnkrqhRESqFrSwcM4Vmdk4YDYQDkx0zq01s6eAZOfcdGACMNnMNuNvUYwNVj1VOTobSldwi4gEEsyWBc65mcDMCtv+p9zjPOC6at7jt0EprpyjV3AXB/ujRES+l3QFN5o6KyJSHYUFEBnhn5RVoG4oEZGAFBZAZHg4oJaFiEhlFBZoNpSISHUUFpQPCw1wi4gEorAAfOH+MQtNnRURCUxhgW5+JCJSHYUFR6fO5mvMQkQkIIUFYGb4wk33sxARqYTCwhMZHqbZUCIilVBYeCIjFBYiIpVRWHh84WHqhhIRqYTCwqOWhYhI5RQWnsiIMPLVshARCUhh4dEAt4hI5RQWnsgIjVmIiFRGYeFRy0JEpHIKC49PYSEiUimFhUfdUCIilVNYeCIjwrQ2lIhIJRQWnsiIMK06KyJSCYWFJ1JXcIuIVEph4dFsKBGRyiksPFruQ0SkcgoLj38hQd1WVUQkEIWFRy0LEZHKKSw8pbOhnFPrQkSkIoWFJzLcADR9VkQkAIWFJzLC/6PQuIWIyPEUFp7IcP+PQuMWIiLHU1h4fBEKCxGRyigsPKUtC13FLSJyPIWFp3TMQosJiogcT2HhiVI3lIhIpRQWHp+6oUREKhXUsDCzkWa20cw2m9kjAV6PMrN3vNcXmVlHb/tgM1vh/bfSzH4UzDrhaDeUrrMQETle0MLCzMKBl4BRQC/gRjPrVWG3O4FDzrkuwHPAM972NcBA51x/YCTwqplFBKtW0NRZEZGqBLNlMRjY7JxLcc4VAG8DYyrsMwaY5D1+D7jYzMw5l+ucK/K2RwNBv1LOp5aFiEilghkWbYDUcs/TvG0B9/HCIROIBzCzc81sLbAauLdceJQxs3vMLNnMktPT00+qWLUsREQqF8ywsADbKrYQKt3HObfIOdcbGAQ8ambRx+3o3Hjn3EDn3MDExMSTKlazoUREKhfMsEgD2pV73hbYVdk+3phEE+Bg+R2cc+uBHKBP0Crl6GwohYWIyPGCGRZLgK5mlmRmkcBYYHqFfaYDt3mPrwXmOOecd0wEgJl1ALoD24JYa7mFBBUWIiIVBW2GkXOuyMzGAbOBcGCic26tmT0FJDvnpgMTgMlmthl/i2Ksd/hw4BEzKwRKgPucc/uDVSto6qyISFWCOh3VOTcTmFlh2/+Ue5wHXBfguMnA5GDWVpG6oUREKqcruD1RalmIiFRKYeHR1FkRkcopLDxhYUZEmCksREQCUFiU4wsP02woEZEAFBblREaEqWUhIhKAwqKcyIgwDXCLiASgsCgnMjyMgqKgr1koIvK9o7AoRy0LEZHAFBbl+FsWxaEuQ0TkjKOwKMcXoamzIiKB1CgszOwBM2tsfhPMbJmZXRrs4k63yPAwCos1ZiEiUlFNWxY/cc4dBi4FEoE7gKeDVlWIaOqsiEhgNQ2L0psUjQbecM6tJPCNi77XfOFh5GuAW0TkODUNi6Vm9in+sJhtZrH4lw6vU6IiwihUy0JE5Dg1XaL8TqA/kOKcyzWzZvi7ouoUTZ0VEQmspi2L84CNzrkMM7sZeAzIDF5ZoeGfOquwEBGpqKZh8TKQa2b9gF8D24F/BK2qENFCgiIigdU0LIqccw4YA/zVOfdXIDZ4ZYWGZkOJiARW0zGLLDN7FLgFGGFm4YAveGWFhsJCRCSwmrYsbgDy8V9vsQdoA/xf0KoKkUhNnRURCahGYeEFxFtAEzO7AshzztW5MYvICP+Yhb/HTUREStV0uY/rgcXAdcD1wCIzuzaYhYVCZHgYzkFRicJCRKS8mo5Z/DcwyDm3D8DMEoHPgfeCVVgo+CL82VlQVIIvXGssioiUqum/iGGlQeE5UItjvzcivYDQ9FkRkWPVtGXxiZnNBqZ6z28AZganpNCJLNeyEBGRo2oUFs65/zSza4Bh+BcQHO+cmxbUykKgtGWRr7AQETlGTVsWOOfeB94PYi0hV9qyUDeUiMixqgwLM8sCAk0NMsA55xoHpaoQKeuGUliIiByjyrBwztW5JT2qUtoNpTELEZFj1bkZTSfDp24oEZGAFBblaIBbRCQwhUU5mjorIhKYwqIcjVmIiASmsCjn6NRZrQ0lIlKewqKc0rDILyoOcSUiImeWoIaFmY00s41mttnMHgnwepSZveO9vsjMOnrbLzGzpWa22vv/RcGss1RibBQAew7nnY6PExH53ghaWHh303sJGAX0Am40s14VdrsTOOSc6wI8Bzzjbd8PXOmcOwu4DZgcrDrLaxQVQWJsFFvTc07Hx4mIfG8Es2UxGNjsnEtxzhUAb+O/h3d5Y4BJ3uP3gIvNzJxzy51zu7zta4FoM4sKYq1lkhJi2LpfYSEiUl4ww6INkFrueZq3LeA+zrkiIBOIr7DPNcBy51x+xQ8ws3vMLNnMktPT009J0Z0SYth2QGEhIlJeMMPCAmyrOM2oyn3MrDf+rqmfBvoA59x459xA59zAxMTEEy60vI4JMezPLiDzSOEpeT8RkbogmGGRBrQr97wtsKuyfcwsAmgCHPSetwWmAbc657YEsc5jJCXEALBNXVEiImWCGRZLgK5mlmRmkcBYYHqFfabjH8AGuBaY45xzZhYHfAw86pz7Jog1HqeTFxYatxAROSpoYeGNQYwDZgPrgXedc2vN7Ckzu8rbbQIQb2abgYeA0um144AuwONmtsL7r3mwai2vXbOGmCksRETKq/HNj06Ec24mFW6/6pz7n3KP84DrAhz3e+D3waytMtG+cNrENVBYiIiUoyu4A9D0WRGRYyksAkhKiGHb/hyc0xpRIiKgsAgoKSGGrPwi9mcXhLoUEZEzgsIigCTNiBIROYbCIgBdayEiciyFRQBt4hrgCzdSFBYiIoDCIqCI8DDaN2vI1v3ZoS5FROSMoLCoRFJCI7btzw11GSIiZwSFRSWSEhqy9UAOJSWaPisiorCoRFJCIwqKStiVeSTUpYiIhJzCohJHZ0SpK0pERGFRiU6J/rBYmZYR4kpEREJPYVGJFo2jGdYlntfmp5CRqyu5RaR+U1hU4fErenH4SCHPf74p1KWIiISUwqIKPVo25sbB7Zm8cDub9maFuhwRkZBRWFTjoUu6ERMZzlMfrdMqtCJSbyksqhHfKIoHftiN+Zv2M2fDvlCXIyISEgqLGrj1vA50Sojhf2dtoKi4JNTliIicdgqLGvCFh/HrkT3YvC+bd5PTQl2OiMhpp7Cooct6t2Bgh6Y89/l35OQXhbocEZHTSmFRQ2bGo6N7kp6Vz2vzU0JdjojIaaWwqIUBHZoyqk9Lxs9LYV9WXqjLERE5bRQWtfTrkT0oKCrh1a/UuhCR+kNhUUtJCTH8oEdzPl61W8uXi0i9obA4AaPPasmew3ksT9UigyJSPygsTsDFPVvgCzdmrd4d6lJERE4LhcUJaBztY0TXRGat2aMlQESkXlBYnKBRfVqyM+MIq9IyQ12KiEjQKSxO0CW9WhARZsxco64oEan7FBYnKK5hJEO7JDBrtbqiRKTuU1ichNF9WrLjYC5rdx0OdSkiIkGlsDgJl/ZuSXiYMUtdUSJSxyksTkKzmEgGdmjKlxvSQ12KiEhQKSxO0vndElm3+zD7s/NDXYqISNAoLE7SiK4JAHyzeX+IKxERCZ6ghoWZjTSzjWa22cweCfB6lJm9472+yMw6etvjzexLM8s2sxeDWePJ6t26CXENfczfpLAQkboraGFhZuHAS8AooBdwo5n1qrDbncAh51wX4DngGW97HvA48HCw6jtVwsOMYZ0TmL8pXVNoRaTOCmbLYjCw2TmX4pwrAN4GxlTYZwwwyXv8HnCxmZlzLsc59zX+0DjjjeiawN7D+Wzel122bWHKAWZq7SgRqSOCGRZtgNRyz9O8bQH3cc4VAZlAfE0/wMzuMbNkM0tOTw/djKTh3rjFPK8r6mBOAT+dvJT73lrGjJW7QlaXiMipEsywsADbKvbT1GSfSjnnxjvnBjrnBiYmJtaquFOpbdOGdEqI4etN/sD686cbyc4vonfrxvzqXytZuv1g2b7OOd0HQ0S+d4IZFmlAu3LP2wIVf80u28fMIoAmwEG+h4Z3TWBhykGW7zjElMU7uGVIB/5557m0iWvA3f9YylffpfPsJxsY8eyX9H3yU/4+dzN5hcWhLltEpEaCGRZLgK5mlmRmkcBYYHqFfaYDt3mPrwXmuO/pKPGIrokcKSzmnslLadowkl9e0o2mMZFMvH0QJc5x28TFvDovhc6JjRic1IxnP9nIxX/+SvfEEJHvhYhgvbFzrsjMxgGzgXBgonNurZk9BSQ756YDE4DJZrYZf4tibOnxZrYNaAxEmtnVwKXOuXXBqvdkDenUjPAwIz0rn6f/4yyaNPAB/tuwvnXXuaxMzeTS3i1IaBQFwIIt+/n9R+v52VvL+OTBEfRo2TiU5YuIVMm+p7/IH2fgwIEuOTk5pDXcMmER2flFvH/vUMLCAg3HHCsjt4BhT8/hop4t+NuNZ5+GCkVEjmVmS51zA6vbT1dwn0Kv3TqQqXcPqVFQgH+Z85vP68DHq3axdX9OwH32Z+fz8ynLeOGLTaxKy9DguIiEhMLiFIr2hRPtC6/VMXcN74QvPIyX524O+Prr87fy8ard/OWz77jqxW8Y/MfPmbJohy4AFJHTSmERYomxUdw4uD0fLNtJ2qHcY17Lzi/irUXbufysViQ/9kOeu6EfnRMb8Ztpq7njzSXsPfy9uGZRROoAhcUZ4J7zO2EG4+elHLP9nSWpZOUVcdeIJBIaRfGjs9sy9e4hPHlVbxamHODS5+YxXRf9ichpoLA4A7SOa8A157Tl7SWpLN9xCICi4hImfr2VQR2bcnb7pmX7hoUZtw3tyMz7R5CUEMP9U5czbsoyDuUUhKp8EakHFBZniF9e0o2WjaO5dcJilu04xKw1e9iZcYS7R3QKuH+nxEa8d+95/Odl3Zm9dg+XPj+PqYt3kFtQdJorF5H6QFNnzyC7Mo5w42sLOZBdQEKjSMyMLx66oNrZVWt3ZfLI+6tZvTOTxtERXDewHfde0JnE2KjTVPmJe/SDVfRrG8fYwe1DXYpIvaSps99DreMa8PY9Q0iMjWLbgVzuHJ5Uo2m4vVs3Yfq4Yfzr3vO4oHtzJi3Yxt3/SKaouKTWNWzbn8N7S9PIyA1+t1ZKejZTF6fy5Ix17Mo4EvTPE5ETF7QruOXEtGriD4wZK3dx3cC2NT7OzBjUsRmDOjbjo94tGDdlOS9+uZkHf9itxu9RUuIYN3UZa3YexhduXNCtOTcObsfFPVucyKlU66NVuzGDYuf448z1vPjjc4LyOSJy8tSyOAO1aBzNXSM6ERVRu2s2Sl3RtzU/OrsNf5uzuWzAvKKNe7LYVuFCwA+W72TNzsM8fGk3bh/akdU7M7hzUjKvz08J+B6lDpzA/cedc0xfuYtBHZvxsws689Gq3Xy75UCt36e+e3nuFlamZoS6DKkHFBZ11G+v6k2L2CgeenclOflFZOcXsSvjCFMW7WDMi19z2fPzuPJvX7NmZyYAuQVF/N/sDfRrF8d9F3bhvy/vxdf/dRGXn9WK33+8vtLA+HDFTgb8/nPGTVlWq9DYuDeLzfuyubJfa352YWfaxDXgyRlrT6jrrL5KPZjLM59s4K9fbAp1KVIPKCzqqCYNfPz5+v5sO5BD7ydm0+eJ2Qx9eg6/mbaa/KISfjO6B7HREdz+xmK27s9h/LwU9h7O5/HLe5aNk/jCw3h+bP9KAyMzt5DffbSONnENmL12D5c8N49py9PYlXGErLxC8gqLWbBlP0/P2sA1Ly/gs3V7y46dsXIX4WHGqD4tifaF8/gVPdmwJ4vJC7ef1p9TKCxKOcAdbywm9WBu9TtXYe7GfQB8vWk/WXmFp6I0kUppzKIOO69zPC/fNIC1uzKJjY4gNtpHr1aN6du2CWbGxT1bcN0r33Lz64s4mFPA5X1bMbBjs2PeozQwAH7/8XrCzPjJ8CQAnp29gYM5Bcz4xXAiwsL49Xsr+eU7K4+rIyLMaNLAx4NvL+fDccPonNiIGSt3M7RzfNkqvJf1bsn53RJ55pMNnN8tkc6JjcqOT0nPZv6m/RQWl5BfVEKPlrFBG0cJtrzCYn79/iq2H8jlhle/ZcrdQ+iYEHNC7zVnwz6ifWHkFZYwZ8M+xvSveCNKOZPkFxWTkp5Dz1bfzxWmFRZ13Mg+LRnZp2XA1zonNuIfPxnM2PELKS5xPDKyR8D9SgOjxDme+mgdvnDjrLZxTFm8gzuGJtG7dRMAPrhvGHM37mNfVj5ZeYXkFhTTp3UThnSOJyuvkCte+Jp7/7mMp67qzY6DuYy7qEvZZ5gZ/3dtXy57fh4Pvr2C9382lMiIMFamZnDzhEVk5R17/ciz1/Tl+kHtqIxzDrOaLeh4Or02L4XtB3J57PKevPTlZq73AqNL80bVH1zOkYJiFmw5wI2D2/Px6t18smbPKQuLzCOFLNi8n0t7tyS8hotiStXSs/L56eRklu3I4LVbB3JJr+/fLzu6zkLYsOcwB3MKGNo5ocr9CopKuO+tZXy+fi/NY6Mwgy9+dSGNomr2O8eCzfu5ecIiGvjCKSguIfmxS8ru+1HqkzV7uPefS/nZhZ0Z3acVN72+kCYNfbxx+yCaN44mzIyf/XMp32zez8s3D+Cy3scH4bvJqbzwxSam3DWE9vENa/6DCLK0Q7n88C9fcVGP5vz9pgFs3JPFTa8vAhwzfjGcVk0a1Pi95mzYy0/eTGbynYOZvXYP7y/dybLHL6FB5IlNiijvsX+v5p8Ld3Bep3ieH9ufFo2jT/o967O1uzK5e1IyB3MLiI+JwjnHZw9dQEwN/94Em66zkBrr0bJxtUEBEBkRxks3nc0PuieyLyuf/7mid42DAmBolwR+PbIHOQXFXNCt+XFBAf6W0I2D2/HKV1v48WsLadzAx9S7h9CleSyNo300iorglZsH0LdtHL+YupyFKcfOoFqZmsFj09aQdugIf5y5vkZ1ZR4p5H9nrWfT3qzjXludlklm7qkZD/jdR+swjMcu7wVA95axvH3PuWTnF/HYtDW1Wkl4zoZ9NIwMZ3BSM0b1acWRwmK++i79pGvMyS/i38t30atVY1akZjDqr/P5csO+k37f+mrZjkNc+/K3OOC9e4fywo392ZWZx/Offxfq0mpNYSG1EhURzqu3DGTGuOFc3rdVrY//6fmd+O2VvXh0dOAuL4DHr+hFUkJMWVC0bXps6yAmKoI3bh9E+2YNuf2NxUxasI2SEsfBnALue2sZibFR3DU8iU/W7mHBlv1V1pN6MJdrXl7Aq1+lcPsbS9hfbkbX7LV7uOqlr3nwneW1OsdA9xz5csM+Zq/dy7iLutA67mgLokvzWB6+tDtfbNhX40UhnXN8uSGdYV0SiIoI59ykZjRt6OOTNcffojcjt4BxU5bx2+lra/TeM1buIju/iKfG9GbGL4bTPDaKO95cwn9PW01OvpaSqa0JX2+lQWQ4H/58GH3aNGFAh2bcOLg9E7/ZxtpdmaEur1YUFlJrkRFhnNW2yQkda2bcPizpmAFwlfS/AAAQNUlEQVTsihpGRjBj3HA+e+h82jUL3I3UNCaSKXedy+CkeJ6YvpabXl/EuCnLSM/K5+Wbz+Hhy7rTJq4BT81YR3ElN4xauv0gV7/0DelZ+Tx5VW/2Z+dz3z+XUVBUwtLth7h/6nIa+ML5cmM663cfrvbc9mTmccOr3/LD575id+bRK9K3H8jhwXdW0L1FLHeNSDruuDuGJdGvXRxPzlhXo+nH3+3NZmfGES7q0RyAiPAwLunVgi/W76Og6OjU41VpGVz+wtd8tGo3by7YxtLtB6t97ymLd9CtRSMGdGhKl+aN+PfPh3H3iCSmLN7ByL/OO64lJ5XLyS/ii/V7GX1WS5qX68p7ZGQPmjb08Ztpayr9s3kmUljIGSkmKoKGkVV3cTVvHM2kOwbx9H+cxeqdmSzYcoAnx/Smb9s4on3h/Ga0fzru20t2lB2TX1TMJ2v2cM8/krnh1YU0io7gg/uGctvQjjx7bV8WbzvIL99ZwV2TltCySTQzfjGcmMhwXp67pcpa5m7cx+gX5rN6Zyb7Dudz4/iF7D2cR1ZeIXdNSvYvQX/rgIAXWoaHGc9e05esvEKenFH9bebneN1CP+jevGzbyD4tycovYvLC7UxbnsYzn2zg2pe/BWDK3eeSGBvFHz5eX2VX15qdmaxKy+THg9uXTQ6I9oXz35f34t2fnkeYGWPHL2Ts+G/5aNWuY4JJjvf5+r3kFZZwVb9jJx40aejj8St6sTI1o9oLXs8kZ8YIi8gJMjPGDm7PiG6JrN2Zecwsk9FntWRwx2Y8PWsDHy7fxcHcAvZk5pGdX0RCoyhuH9qR+37QhWYxkQCM6d+G9buzeOWrLTSLieTNOwaTlBDDTUM68Pr8FB6+tPtxA+b5RcX85bPvePWrFHq0jOWlm84hI7eAWycs5sbxC2nXrCEp+3OY/JPBdIivfIps95ax/PwHXXj+801s3JPF6LNacX63BNbuOsycDftYvPUgSQkxnN8tgS83pNOrVWNaNjn62+qwLgnERkfwu4+Ohs1FPZrzp+v60Swmkocu6cajH6zmkzV7GHVW4O7DKYt3EO0L40fnHL/MzKCOzZj1wAjeXLCNKYt2MG7KchIaRTI4qRlntYmjf7s4hnRqdkbOQAuVGSt30bJxNAM7ND3utav6teaTNXv406cbGdYlgT5tTqylfjppNpTUaRv2HOa/3l9NA18YTRtGktAoiot7Nmd4lwQiwo9vWBeXOF6bn8KIrgllU4L3Hs5jxDNfct3AtvzhR2eV7bsqLYNfvbuSTfuyuXFwe564slfZbXWXbDvIbRMXk1tQzJNX9ea2oR2rrbWouISpi3cwY+Vulmw/SOlfzfbNGjK0czxb0rNZtiOD4hLH/Rd14aFLux9z/JqdmaRn59OuaUPaNm1wzC1+i4pLGPXX+RQWl/DpLy8gMuLYc8/OL+LcP3zOqLNa8afr+lVZZ3GJY9536XywfCcrUzPY4V1ceP/FXXnokpqvRVZRTn4R33mTDHq3bnJcjWealPRsDuUWMiBAGGTmFjLwD59x23kdeeyKXgGPP5RTwGXPz6NxAx8f/WJ4rW/JfKrUdDaUwkKkBh79YBXvL9vJzPtHsCU9m7kb9/FuchqJjaJ4+pqzuLBcl1CplakZrN99mBsGtav1b9x7D+exMOUAvVs3oXNiTNnxh/MKWZWayTkd4qrtpquodLrt7UM70rl5I7LyCsnMLSQ9K58t6dmsTMvk/Z8NDfiPX1Uycgt4YvpaZqzcxb/uPY8BHZpVf1A5L325mX8lp7L9YG5ZQEZFhNG/XRyj+rTk1vM61mj15fKy84v4eNUuruzXutY/p5rYn53PyOfnk5VXyOwHzz/uwsp3l6Ty6/dXMX3cMPq2jav0feZ9l86tExdz+9CO/Paq3lV+Zl5hMWac8JpxlVFYiJxC2/bncNGf51I6HtnAF86Y/q15dHTPgFOAz0TOOW6ZsJivNx+dIRYZEUbz2CgSY6Po1zaOJ67sdUJdSVl5hYx+YT4AM+8fQWz00Z9JXmEx7yxJZfy8FH7QI5HfjelT9hkfrtjJA2+v4LxO8ZzXOZ4eLWMpKnEkbzvEwpQDrNt9mEt6teAv1/c75j2rsj87n9vfWMyanYcZnNSMN24fdEqvaSgpcfxk0hIWbDlAZHgY/do14Z93nnvMz+2WCYvYcTCXuQ9fWO3P88kZa3njm22EGUSEhRHtC+NnF3bh3gs6lR07e+0eHnpnBXlFJXSIb0jX5o246dwOnN8t8aTPR2EhcopNXridfYfzGN4lgbPbNz3ju0kCOVJQzK7MI/7lX6J8RPvCTtk4Q/K2g1z/6rdcfXYbnryqNxv3ZLF8RwYTv9nK7sw8khJi2Lo/h7tHJPGb0T3Zkp7NVS9+Q+/WjZly9xB8FboFnXO8uWAbv/94PR3iG/L4Fb3YnZHHml2ZZOQWcHa7ppzbqRm9WjUu61JMPZjLLRMWsedwHred15HXv97K2e3iePMng2t1TVB563cfJiLM6NoiFvBPh/3dR+t4akxvwsx47N9r+NN1/bh2gH+sJz0rn3P/+Dn3XdiFhy/rXtVbA/4wnbp4BwdzCigqcWzYfZgvN6Zzaa8W/On6fkz+djv/N3sj/do24fxuiWzam83KtAz2Hs7jyTF9uGVIhxM6r1IKCxE57f7y2Xe8UGEV3HPax/HQJd0Z1iWe305fy6Rvt/OLi7owe+0eDmQX8PH9I44ZrK9oYcoBfv7WMg5495mPjY6gSQMfaYf805OjIsJI9FpHOw7kUlTimHj7IAZ0aMrM1bu5f+pyzmrbhMcu70X/dnE1WsIkr7CYj1btZvK321iZ5r8eomerxlzSszkvf7WFC7o157VbB+AcXP/qt2xOz+bzhy5g56EjvPTlZj5dt5dPf3k+3byAqQ3nHBO+3sr/ztpAQ184WflFXNWvNc9e27dsXCMnv4j7py7niw37uOf8Tjwysketu+pKKSxE5LQrKi7hr19sItoXTs9WsXRv2ZjWTaLLWi8lJY5f/Wsl05bvxAwm/+RchnetfvWAfVl5rErNpHvLWNo2bYCZsSczj0VbD7B212HSs/JJz/Jfo/LElb3KWgHgX0Lm/reXU1BUQlxDHyO6JjK0czyDk5rRKSGGvMISVu/MZEXqIdbvzmL97sOkpOdQUFxC58SYst/cpy3fycq0TFo0jmLWA+eXzaLbtDeL0S/Mp2FkBJlHCmngC+e2oR15ZFTlF57WxOKtB3ns36sZ078N913Y+bgWYFFxCU/OWMfkhdu55py2/Pn6qicmVEZhISJnpKLiEp76aB1dW8SedBdKTWXkFjB/037mbkxn3qb0smCJa+gjK6+o7OK4Vk2i6d4ylu4tY7mgayLndY4/5h/pbftziPaFH9cSmvD1Vmas3MU157RhzNltaFzD8ZWT5Zx/9l7H+BguDbBOWk0oLEREAnDOsXV/Dou3HmT5jgyaN46if7s4+rWLK1syvz6paVjoojwRqVfMjE6JjeiU2Iixg9uHupzvje/fdA4RETntFBYiIlIthYWIiFRLYSEiItVSWIiISLUUFiIiUi2FhYiIVEthISIi1aozV3CbWTqw/STeIgHYX+1edUt9PGeon+etc64/anveHZxz1a51XmfC4mSZWXJNLnmvS+rjOUP9PG+dc/0RrPNWN5SIiFRLYSEiItVSWBw1PtQFhEB9PGeon+etc64/gnLeGrMQEZFqqWUhIiLVUliIiEi16n1YmNlIM9toZpvN7JFQ1xMMZtbOzL40s/VmttbMHvC2NzOzz8xsk/f/pqGuNRjMLNzMlpvZR97zJDNb5J33O2YWGeoaTyUzizOz98xsg/edn1cfvmsz+6X353uNmU01s+i6+F2b2UQz22dma8ptC/j9mt8L3r9vq8zsnBP93HodFmYWDrwEjAJ6ATeaWa/QVhUURcCvnHM9gSHAz73zfAT4wjnXFfjCe14XPQCsL/f8GeA577wPAXeGpKrg+SvwiXOuB9AP/7nX6e/azNoA9wMDnXN9gHBgLHXzu34TGFlhW2Xf7yigq/ffPcDLJ/qh9TosgMHAZudcinOuAHgbGBPimk4559xu59wy73EW/n882uA/10nebpOAq0NTYfCYWVvgcuB177kBFwHvebvUqfM2s8bA+cAEAOdcgXMug3rwXeO/TXQDM4sAGgK7qYPftXNuHnCwwubKvt8xwD+c30Igzsxancjn1vewaAOklnue5m2rs8ysI3A2sAho4ZzbDf5AAZqHrrKgeR74NVDiPY8HMpxzRd7zuvaddwLSgTe8rrfXzSyGOv5dO+d2An8CduAPiUxgKXX7uy6vsu/3lP0bV9/DwgJsq7Nzic2sEfA+8KBz7nCo6wk2M7sC2OecW1p+c4Bd69J3HgGcA7zsnDsbyKGOdTkF4vXRjwGSgNZADP4umIrq0nddE6fsz3t9D4s0oF25522BXSGqJajMzIc/KN5yzn3gbd5b2iT1/r8vVPUFyTDgKjPbhr+L8SL8LY04r6sC6t53ngakOecWec/fwx8edf27/iGw1TmX7pwrBD4AhlK3v+vyKvt+T9m/cfU9LJYAXb0ZE5H4B8Smh7imU87rp58ArHfO/aXcS9OB27zHtwEfnu7agsk596hzrq1zriP+73aOc+4m4EvgWm+3OnXezrk9QKqZdfc2XQyso45/1/i7n4aYWUPvz3vpedfZ77qCyr7f6cCt3qyoIUBmaXdVbdX7K7jNbDT+3zbDgYnOuT+EuKRTzsyGA/OB1Rztu/8N/nGLd4H2+P+yXeecqzhwVieY2YXAw865K8ysE/6WRjNgOXCzcy4/lPWdSmbWH/+AfiSQAtyB/xfDOv1dm9mTwA34Z/8tB+7C3z9fp75rM5sKXIh/KfK9wBPAvwnw/XrB+SL+2VO5wB3OueQT+tz6HhYiIlK9+t4NJSIiNaCwEBGRaiksRESkWgoLERGplsJCRESqpbAQOQOY2YWlq+KKnIkUFiIiUi2FhUgtmNnNZrbYzFaY2avevTKyzezPZrbMzL4ws0Rv3/5mttC7j8C0cvcY6GJmn5vZSu+Yzt7bNyp3H4q3vAuqRM4ICguRGjKznvivEB7mnOsPFAM34V+0bplz7hzgK/xX1AL8A/gv51xf/FfPl25/C3jJOdcP//pFpcsvnA08iP/eKp3wr20lckaIqH4XEfFcDAwAlni/9DfAv2BbCfCOt88/gQ/MrAkQ55z7yts+CfiXmcUCbZxz0wCcc3kA3vstds6lec9XAB2Br4N/WiLVU1iI1JwBk5xzjx6z0ezxCvtVtYZOVV1L5dcsKkZ/P+UMom4okZr7ArjWzJpD2X2PO+D/e1S6sumPga+dc5nAITMb4W2/BfjKu49Impld7b1HlJk1PK1nIXIC9JuLSA0559aZ2WPAp2YWBhQCP8d/g6HeZrYU/x3abvAOuQ14xQuD0tVfwR8cr5rZU957XHcaT0PkhGjVWZGTZGbZzrlGoa5DJJjUDSUiItVSy0JERKqlloWIiFRLYSEiItVSWIiISLUUFiIiUi2FhYiIVOv/AQLHIBRgkgpGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[cols_input].values\n",
    "\n",
    "y_test = df_test['OUTPUT_LABEL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 178)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test_tf = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns_t = ['Mean_time', 'StandarS_time','Kurt_time',\n",
    "               'Skewness_time','Activity_time', 'Complexity_time','Morbidity_time','Mad_time']\n",
    "Y_columns_t = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st = pd.DataFrame(columns = X_columns_t)\n",
    "y_test_st = pd.DataFrame(columns = Y_columns_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_time</th>\n",
       "      <th>StandarS_time</th>\n",
       "      <th>Kurt_time</th>\n",
       "      <th>Skewness_time</th>\n",
       "      <th>Activity_time</th>\n",
       "      <th>Complexity_time</th>\n",
       "      <th>Morbidity_time</th>\n",
       "      <th>Mad_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310854</td>\n",
       "      <td>0.330537</td>\n",
       "      <td>-0.329556</td>\n",
       "      <td>0.193588</td>\n",
       "      <td>0.205885</td>\n",
       "      <td>0.490538</td>\n",
       "      <td>2.613884</td>\n",
       "      <td>0.231769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.660874</td>\n",
       "      <td>1.162641</td>\n",
       "      <td>1.684505</td>\n",
       "      <td>0.991490</td>\n",
       "      <td>1.788489</td>\n",
       "      <td>0.266811</td>\n",
       "      <td>1.977902</td>\n",
       "      <td>0.340305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_time  StandarS_time  Kurt_time  Skewness_time  Activity_time  \\\n",
       "0   0.310854       0.330537  -0.329556       0.193588       0.205885   \n",
       "1  -0.660874       1.162641   1.684505       0.991490       1.788489   \n",
       "\n",
       "   Complexity_time  Morbidity_time  Mad_time  \n",
       "0         0.490538        2.613884  0.231769  \n",
       "1         0.266811        1.977902  0.340305  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    activity, morbidity, complexity = hjorth(X_test_tf[i])\n",
    "    mad = nk.mad(X_test_tf[i])\n",
    "    X_test_st.loc[i] = np.array([np.mean(X_test_tf[i]), np.std(X_test_tf[i]), \n",
    "                                         scipy.stats.kurtosis(X_test_tf[i]),\n",
    "                                         scipy.stats.skew(X_test_tf[i]),\n",
    "                                         activity, morbidity, complexity, mad])\n",
    "    y_test_st.loc[i] = y_test[i]\n",
    "X_test_st.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st.to_csv('X_test_st.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 1, 178) (1725, 8)\n"
     ]
    }
   ],
   "source": [
    "X_test_tf = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "print(X_test_tf.shape, X_test_st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model.predict([X_test_tf,X_test_st])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "AUC:0.984\n",
      "accuracy:0.919\n",
      "recall:0.970\n",
      "precision:0.713\n",
      "specificity:0.915\n",
      "prevalence:0.192\n",
      " \n"
     ]
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "print('Test:')\n",
    "mode_auc, knn_accuracy, model_recall, \\\n",
    "     model_precision, model_specificity = print_report(y_test,y_test_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725/1725 [==============================] - 0s 148us/step\n",
      "[0.07199846181039955, 0.9194203019142151]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([X_test_tf,X_test_st ], y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
